# Flow Registry Framework v1 version documentation

This page documents capabilities of _v1_ version of Flow Registry.
This version is the current stable version that should be used to develop
with Duo Agent Platform

[[_TOC_]]

## YAML Configuration Structure

YAML configuration files define the structure and behavior of your flows.
Every flow YAML file must contain these top-level sections that specify components, routing logic, and execution
parameters.

```yaml
version: "v1"
environment: ambient

components:
# List of components (see Component Types section)

routers:
# Define flow between components (see examples below)

flow:
    entry_point: "component_name"  # Name of first component to run
```

### Required Fields

- **version**: Always use `"v1"` for the current framework version
- **environment**: Indicate how AI feature implemented by given flow config will operate within Duo Agent Platform, refer to [environment](#environment) section for more details
- **components**: List of components that make up your flow, for more details see the main documentation [page](index.md#key-framework-concepts)
- **routers**: Define how components connect to each other, for more details see the main documentation [page](index.md#routers)
- **flow**: Specify the entry point component and other options, for more details see the main documentation [page](index.md#flow)
- **prompts**: List of inline prompt templates for flow components to use, for more details see this [paragraph](#prompts)

### Environment

Flow environment declares expected level of interaction between a human and an AI agent,
Flow Registry `v1` version uses following environments:

| environment      | description |
| -----------------| ----------- |
| **chat**         | Designed for the most collaborative experience, where a human and an AI Agent work alongside each other via back and forth conversation within chat-like interface |
| **chat-partial** | A variation of `chat` environment, designed for efficiency of development, by skipping over all boiler plate for single agent `chat` flows. It offers the same level of interactiveness as `chat` environment |
| **ambient**      | Designed for hands-off experience, when a human delegates assignment to an agent to be completed in a background. The delegation can be done directly by the human, or even via configured trigger event in GitLab platform. The human participation in `ambient` flows should be as minimal as possible |

## Quick Start

This section provides a step-by-step approach to creating your first flow.
Follow these steps to build a basic AI agent flow that can interact with the repository files and respond to user
requests.

1. Create a YAML file in [`duo_workflow_service/agent_platform/v1/flows/configs/`](duo_workflow_service/agent_platform/v1/flows/configs) which will configure your
   flow. A name of the file will become flow identifier used to trigger it later on. The file should has this basic
   structure:

   ```yaml
   version: "v1"
   environment: ambient
   components:
      - name: "my_agent" # should use alphanumeric characters or underscore. Must not include characters such as : and .
        type: AgentComponent
        prompt_id: "your_prompt_id"
        prompt_version: "^1.0.0"
        inputs: ["context:goal"]
        toolset: ["read_file", "create_file_with_contents"]
   routers:
      - from: "my_agent"
        to: "end"
   flow:
      entry_point: "my_agent"
   ```

1. Create a prompt template in the AI Gateway prompt registry at
   `ai_gateway/prompts/definitions/your_prompt_id/base/1.0.0.yml`:

   ```yaml
   name: Your prompt name
   model:
      params:
        model_class_provider: anthropic
        max_tokens: 32_768
      unit_primitives: []
   prompt_template:
      system: |
        You are GitLab Duo Chat, an agentic AI Coding assistant built by GitLab.
        Your role is to help the user complete their request by using the available tools.
        Your response style is concise and actionable.
      user: |
        Here is my task:
        {{goal}}
      placeholder: history  # See Message Placeholders section in AI Gateway Prompt Registry docs
   params:
      timeout: 180
   ```

1. Accessing the new Flow

   Currently, accessing flows via gRPC is not fully implemented.
   To use your new flow in the Duo Chat interface within VSCode, follow this workaround:

    1. In the workflow registry file `duo_workflow_service/server.py`, uncomment the line:

       ```python
       workflow_class: FlowFactory = resolve_workflow_class("<yaml_file_name_without_extension>/v1")
       ```

    1. After making this change, your new flow will be available in the Duo Chat interface for interaction in VSCode

## Component Types

### AgentComponent

The AgentComponent is the primary building block for AI-powered flows.
An AgentComponent uses a Large Language Model (LLM) to process inputs and generate responses. It provides these
capabilities:

- Execute tools to interact with the environment (read files, run commands, etc.)
- Maintain conversation history for context
- Make decisions based on the provided prompt and available tools
- Generate structured outputs that other components consume

The agent uses the prompt template from the prompt registry, processes the inputs through the LLM, and calls tools as
needed to complete its task.

#### Required Parameters

- **name**: Unique identifier for this component instance. Must not contain `:` or `.` characters.
- **type**: Must be `"AgentComponent"`
- **prompt_id**: ID of the prompt template from either the prompt registry or locally defined prompts

#### Optional Parameters

- **prompt_version**: Semantic version constraint (e.g., `"^1.0.0"`). If omitted or `null`, uses locally defined prompt
  from flow YAML.
- **inputs**: List of input data sources (default: `["context:goal"]`)
- **toolset**: List of tools available to the agent
- **ui_log_events**: UI logging configuration
- **ui_role_as**: Display role in UI (`"agent"` or `"tool"`)

#### Available Tools

Agents access the following tools in their `toolset` configuration.
Complete list of tools classes can be located at `duo_workflow_service/components/tools_registry.py`. To configure an
agent with tools, pass `name` attributes from their classes, eg: for `GetIssue` tool class pass `get_issue`
Each tool is a Python class that the agent calls to perform specific actions.

Here are some examples:

- **read_file**: Read contents of a file
- **create_file_with_contents**: Create a new file with specified content
- **edit_file**: Modify an existing file
- **list_dir**: List directory contents
- **find_files**: Search for files matching patterns

#### Prompts

Prompts define how the AI agent behaves and responds to inputs.
Every AgentComponent requires a prompt that serves as the "instructions" for the AI agent, defining its personality,
capabilities, and response patterns.
Prompts include placeholders that get replaced with actual data from the flow state.

**Important for Multi-turn Conversations:** If your AgentComponent needs access to conversation history (for context in
multi-turn interactions), include `placeholder: history` in your prompt template. This automatically provides the
component's conversation history to the AI model.

##### Prompt Sources

Flows can use prompts from two sources:

1. **File-based Prompts**: Traditional prompts stored in the AI Gateway prompt registry at
   `ai_gateway/prompts/definitions/`. Reference these using both `prompt_id` and `prompt_version` (e.g.,
   `prompt_version: "^1.0.0"`).

1. **Locally Defined Prompts**: Prompts defined directly within the flow YAML configuration. Reference these by setting
   `prompt_version: null` or omitting the `prompt_version` field entirely.

##### Locally Defined Prompts

Flows can define prompts locally within their YAML configuration, eliminating the need for separate prompt definition
files. This approach is particularly useful for flow-specific prompts or rapid prototyping.

To define prompts locally, add a `prompts` section to your flow YAML:

```yaml
version: "v1"
environment: ambient

components:
    - name: "code_analyzer"
      type: AgentComponent
      prompt_id: "my_local_prompt"
      # prompt_version omitted - uses local prompt
      ui_log_events: [ "on_agent_final_answer" ]
      inputs: ["context:goal"]
      toolset: ["read_file", "list_dir"]

prompts:
    - prompt_id: "my_local_prompt"
      model:
        params:
            model_class_provider: anthropic
            model: claude-sonnet-4-20250514
            max_tokens: 32_768
      prompt_template:
          system: "You are a helpful assistant specialized in code analysis"
          user: "{{goal}}"
          placeholder: history  # Optional: include conversation history
      params:
          timeout: 180

routers:
    - from: "code_analyzer"
      to: "end"

flow:
    entry_point: "code_analyzer"

```

**Routing Logic**: The system automatically routes between local and file-based prompts:

- `prompt_version: null` or omitted → Use local prompt from flow YAML
- `prompt_version: "^1.0.0"` → Use file-based prompt from prompt registry

**Local Prompt Structure**:

Mirrors the prompt structure of prompts taken from the prompt registry. More information about the structure can be
found [here](../aigw_prompt_registry.md#ai-gateway-prompt-configuration-reference).

**Benefits of Local Prompts**:

- **Rapid Development**: No need to create separate prompt files
- **Flow Coupling**: Prompts stay co-located with their usage
- **Simplified Testing**: Easy to iterate on prompts during development
- **Self-Contained**: Flows become more portable and self-documented

For detailed information about prompt templates and placeholder configuration, see
the [AI Gateway Prompt Registry Documentation](../aigw_prompt_registry.md#message-placeholders).

#### Inputs

Agent inputs work together with prompt placeholders to provide dynamic data to the AI.
When you define inputs in your component configuration, that data becomes available as template variables in your
prompt.

For example:

```yaml
# In your flow YAML:
inputs:
    - from: "context:user_request"
      as: "task_description"
    - from: "context:analyzer.findings"
      as: "analysis_results"
```

```yaml
# In your prompt template:
user: |
    Task: {{task_description}}
    Analysis: {{analysis_results}}
    Please provide a solution.
```

#### Outputs

Each AgentComponent automatically produces:

- **context:{component_name}.final_answer**: The agent's final response
- **conversation_history:{component_name}**: Message history
- **status**: Updated workflow status

These outputs can be used as inputs by other components or referenced in routing logic to control flow execution.
For example, you might route to different components based on whether the agent's final answer equals to specific phrase

#### UI Log Events

The AgentComponent supports the following UI log events that can be specified in the `ui_log_events` configuration:

- **on_agent_final_answer**: Logged when the agent produces its final response. This event captures the agent's
  conclusion or final output and displays it in the UI.
- **on_tool_execution_success**: Logged when a tool is successfully executed by the agent. This shows users what actions
  the agent took and their successful results.
- **on_tool_execution_failed**: Logged when a tool execution fails. This provides error information and helps with
  debugging failed operations.

#### Complete AgentComponent Example

```yaml
components:
    - name: "code_assistant"
      type: AgentComponent
      prompt_id: "code_review_helper"
      prompt_version: "^1.0.0"
      inputs: [ "context:goal" ]
      toolset:
          - "read_file"
          - "list_dir"
          - "find_files"
          - "create_file_with_contents"
          - "edit_file"
      ui_log_events:
          - "on_agent_final_answer"
          - "on_tool_execution_success"
          - "on_tool_execution_failed"
      ui_role_as: "agent"
```

### DeterministicStepComponent

The DeterministicStepComponent executes a **single tool** deterministically with predetermined arguments extracted from the flow state. This component provides a way to run one specific tool without AI involvement, using inputs to extract the necessary parameters and producing predictable outputs following fixed conventions.

The component provides these capabilities:

- **Execute a single tool deterministically**: Run one designated tool with parameters derived from inputs
- **Extract parameters from state**: Use component inputs to gather the tool's execution arguments
- **No AI involvement**: Direct tool execution without LLM processing
- **Integration with existing toolsets**: Compatible with any registered tool in the toolset
- **Chainable design**: Multiple DeterministicStepComponents can be chained to execute sequential tool operations

Unlike AgentComponent or OneOffComponent which use AI to determine tool usage, DeterministicStepComponent executes exactly one pre-specified tool with arguments extracted directly from the flow state, making it ideal for predictable, repeatable operations. **To execute multiple tools, chain multiple DeterministicStepComponents together in your flow.**

#### Required Parameters

- **name**: Unique identifier for this component instance. Must not contain `:` or `.` characters.
- **type**: Must be `"DeterministicStepComponent"`
- **tool_name**: Name of the single tool to execute

#### Optional Parameters

- **toolset**: Toolset containing the tool to be executed. (If no toolset is specified, a new one is created with only the `tool_name`)
- **inputs**: List of input data sources to extract tool parameters (default: empty list)
- **ui_log_events**: UI logging configuration for displaying tool execution
- **ui_role_as**: Display role in UI (default: `"tool"`)

#### Outputs

Each DeterministicStepComponent automatically produces:

- **ui_chat_log**: UI logging information for tool execution events
- **context:{component_name}.tool_responses**: Record of successful tool execution results
- **context:{component_name}.error**: Record of any errors during the tool call
- **context:{component_name}.execution_result**: Status of the execution ("success" or "failed")

#### Complete DeterministicStepComponent Example

##### Execute a single tool

```yaml
components:
   - name: "read"
     type: DeterministicStepComponent
     inputs:
       - from: "context:goal"
         as: "file_path"
     tool_name: "read_file"
     ui_log_events:
       - "on_tool_execution_success"
       - "on_tool_execution_failed"
```

##### Chain multiple tools

```yaml
components:
    - name: "read_config"
      type: DeterministicStepComponent
      inputs:
          - from: "context:goal"
            as: "config_path"
      tool_name: "read_file"
    - name: "backup_config"
      type: DeterministicStepComponent
      inputs:
          - from: "context:read_config.tool_responses"
            as: "contents"
          - from: "config_backup.txt"
            as: "file_path"
            literal: true
      tool_name: "create_file_with_contents"
```

#### Validation

The DeterministicStepComponent performs automatic validation of tool arguments:

- Validates that the specified tool exists in the provided toolset
- Checks that all required tool parameters are configured in the inputs
- Verifies that configured parameters match the tool's expected schema
- Raises clear validation errors during component initialization if configuration is invalid

This validation ensures that tool execution errors are caught at configuration time rather than runtime.

### OneOffComponent

The `OneOffComponent` functionally sits in-between the `AgentComponent` and the `DeterministicStepComponent`.
`OneOffComponent` works by taking a pre-defined toolset with an input and generating tool calls in a single round, then
finally exiting when those tool calls have been successfully executed.
The component has the ability to retry failed tool executions and iterate up to the `max_correction_attempts`.

The `OneOffComponent` is designed for scenarios where you need to execute one or more tool operations in a single round
with built-in error handling and retry logic.
Unlike the `AgentComponent` which can engage in multi-turn conversations and generate additional tool calls after seeing
results,
`OneOffComponent` is constrained to a single round of tool generation and execution.

**Note:** If your OneOffComponent prompt needs access to conversation history from previous interactions, include
`placeholder: history` in your prompt template.

#### Key Features

- **Single Round Tool Execution**: Executes one or more tool calls in a single round and exits upon successful
  completion
- **Multiple Tool Support**: Can use multiple tools from its toolset as needed to complete the task
- **Error Correction**: Automatically retries failed tool executions with error feedback
- **Configurable Retry Logic**: Set maximum correction attempts via `max_correction_attempts` parameter
- **Built-in Tool Routing**: Intelligent routing between LLM and tool nodes based on execution results
- **UI Logging**: Comprehensive logging of tool execution states and results

#### Required Parameters

- **name**: Unique identifier for this component instance
- **type**: Must be `"OneOffComponent"`
- **prompt_id**: ID of the prompt template from either the prompt registry or locally defined prompts
- **toolset**: List of tools available to the component

#### Optional Parameters

- **prompt_version**: Semantic version constraint (e.g., `"^1.0.0"`). If omitted or `null`, uses locally defined prompt
  from flow YAML.
- **inputs**: List of input data sources (default: `["context:goal"]`)
- **max_correction_attempts**: Maximum number of retry attempts for failed tool executions (default: 3)
- **ui_log_events**: UI logging configuration for displaying tool execution progress

#### Internal Architecture

The OneOffComponent consists of three internal nodes:

1. **LLM Node** (`{name}#llm`): Uses `AgentNode` to generate one or more tool calls based on the prompt and inputs
1. **Tools Node** (`{name}#tools`): Executes all generated tool calls with error correction using
   `ToolNodeWithErrorCorrection`
1. **Exit Node** (`{name}#exit`): Handles component completion and state logging

The component uses conditional routing to handle tool execution results:

- **Success**: Routes to exit node when all tool executions complete successfully
- **Retry**: Returns to LLM node when errors occur and retry attempts remain
- **Max Attempts**: Routes to exit node when maximum correction attempts are reached

#### Comparison with AgentComponent

The OneOffComponent and AgentComponent differ in their execution patterns:

**OneOffComponent**:

- **Single Round**: Generates tool calls once and executes them all in one round
- **Task-Focused**: Designed for specific, bounded tasks that can be completed in one execution cycle
- **No Iterative Reasoning**: Cannot see tool results and decide on additional actions
- **Simpler Flow**: Linear progression from tool generation → execution → completion
- **Error Handling**: Built-in retry logic for failed tool executions

**AgentComponent**:

- **Multi-Turn Conversations**: Can generate tools, see results, and decide on next actions
- **Iterative Decision Making**: Can analyze tool results and generate additional tool calls
- **Complex Reasoning**: Supports back-and-forth between LLM and tools until task completion
- **Final Output Control**: Uses `AgentFinalOutput` tool to explicitly signal completion
- **Conversation Flow**: Maintains ongoing conversation history for context

**When to Use Each**:

- Use **OneOffComponent** for: File operations, data processing, single API calls, or any task that can be completed in
  one execution round
- Use **AgentComponent** for: Interactive tasks, complex problem-solving, multi-step workflows requiring decision-making
  between steps

#### Outputs

Each OneOffComponent automatically produces:

- **ui_chat_log**: UI logging information for tool execution events
- **conversation_history:{component_name}**: Message history for the component
- **context:{component_name}.tool_calls**: Record of tool calls made by the component
- **context:{component_name}.tool_responses**: Record of tool responses received
- **context:{component_name}.execution_result**: Execution result ("success" or "failed")

#### UI Log Events

The OneOffComponent supports the following UI log events from `UILogEventsOneOff` that can be specified in the
`ui_log_events` configuration:

- **on_tool_call_input**: Logged when a tool is about to be called with its input arguments
- **on_tool_execution_success**: Logged when a tool executes successfully
- **on_tool_execution_failed**: Logged when a tool execution fails

#### Complete OneOffComponent Example

```yaml
components:
    - name: "file_reader"
      type: OneOffComponent
      prompt_id: "read_specific_file"
      prompt_version: "^1.0.0"
      inputs:
          - from: "context:goal"
            as: "target_file"
      toolset:
          - "read_file"
      max_correction_attempts: 2
      ui_log_events:
          - "on_tool_call_input"
          - "on_tool_execution_success"
          - "on_tool_execution_failed"
```

#### Usage Patterns

**Single File Operation**: Use OneOffComponent for singular file operations:

```yaml
components:
    - name: "config_updater"
      type: OneOffComponent
      prompt_id: "update_config_file"
      prompt_version: "^1.0.0"
      inputs:
          - "context:goal"
      toolset:
          - "edit_file"
      max_correction_attempts: 3
```

**Conditional Tool Execution**: Only proceeds when tool call was a success:

```yaml
routers:
    - from: "file_processor"
      condition:
          input: "context:file_processor.execution_result"
          routes:
              "success": "next_step"
              "failed": "error_handler"
```

**Error Handling Integration**: Combine with other components for robust workflows:

```yaml
components:
    - name: "backup_creator"
      type: OneOffComponent
      prompt_id: "create_backup"
      prompt_version: "^1.0.0"
      toolset: [ "create_file_with_contents" ]
      max_correction_attempts: 5

    - name: "error_reporter"
      type: AgentComponent
      prompt_id: "report_errors"
      prompt_version: "^1.0.0"
      inputs:
          - from: "context:backup_creator.tool_responses"
            as: "execution_results"
      toolset: [ "create_issue" ]

routers:
    - from: "backup_creator"
      condition:
          input: "context:backup_creator.execution_result"
          routes:
              "success": "next_step"
              "failed": "error_reporter"
    - from: "error_reporter"
      to: "end"  # Always end after error reporting
```

## Flow Examples

### Simple ambient code review flow

```yaml
version: "v1"
environment: ambient

components:
    - name: "code_analyzer"
      type: AgentComponent
      prompt_id: "code_review_prompt"
      # prompt_version omitted - uses local prompt
      ui_log_events: ["on_agent_final_answer"]
      inputs:
        - from: context:goal
          as: mr_link
      toolset: ["read_file", "list_dir"]

prompts:
    - prompt_id: "my_local_prompt"
      model:
        params:
            model_class_provider: anthropic
            model: claude-sonnet-4-20250514
            max_tokens: 32_768
      prompt_template:
          system: "You are a experience software developer, your role is to conduct through code review and mentor other engineers on best practices and patterns."
          user: "Please conduct code review for merge request at: {{mr_link}}"
          placeholder: history  # Optional: include conversation history
      params:
          timeout: 180

routers:
    - from: "code_analyzer"
      to: "end"

flow:
    entry_point: "code_analyzer"
```

### Chat-partial flow for conversational code review foundational agent

```yaml
version: "v1"
environment: chat-partial

components:  # Exactly 1 component may be present in components section, and it must be of type AgentComponent
    - name: "code_analyzer"
      type: AgentComponent
      prompt_id: "code_review_prompt"
      # prompt_version omitted - uses local prompt
      ui_log_events: ["on_agent_final_answer"]
      inputs:
        - from: context:goal
          as: mr_link
      toolset: ["read_file", "list_dir"]

prompts:
    - prompt_id: "my_local_prompt"
      model:
        params:
            model_class_provider: anthropic
            model: claude-sonnet-4-20250514
            max_tokens: 32_768
      prompt_template:
          system: "You are a experience software developer, your role is to conduct through code review and mentor other engineers on best practices and patterns."
          user: "Please conduct code review for merge request at: {{mr_link}}"
          placeholder: history  # Optional: include conversation history
      params:
          timeout: 180

routers: []
flow: {}
```

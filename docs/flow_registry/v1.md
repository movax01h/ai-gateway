# Flow Registry Framework v1 version documentation

This page documents capabilities of _v1_ version of Flow Registry.
This version is the current stable version that should be used to develop
with Duo Agent Platform

[[_TOC_]]

## YAML Configuration Structure

YAML configuration files define the structure and behavior of your flows.
Every flow YAML file must contain these top-level sections that specify components, routing logic, and execution
parameters.

```yaml
version: "v1"
environment: ambient

components:
# List of components (see Component Types section)

routers:
# Define flow between components (see examples below)

flow:
    entry_point: "component_name"  # Name of first component to run
```

### Required Fields

- **version**: Always use `"v1"` for the current framework version
- **environment**: Indicate how AI feature implemented by given flow config will operate within Duo Agent Platform, refer to [environment](#environment) section for more details
- **components**: List of components that make up your flow, for more details see the main documentation [page](index.md#key-framework-concepts)
- **routers**: Define how components connect to each other, for more details see the main documentation [page](index.md#routers)
- **flow**: Specify the entry point component and other options, for more details see the main documentation [page](index.md#flow)
- **prompts**: List of inline prompt templates for flow components to use, for more details see this [paragraph](#prompts)

### Environment

Flow environment declares expected level of interaction between a human and an AI agent,
Flow Registry `v1` version uses following environments:

| environment      | description |
| -----------------| ----------- |
| **chat**         | Designed for the most collaborative experience, where a human and an AI Agent work alongside each other via back and forth conversation within chat-like interface |
| **chat-partial** | A variation of `chat` environment, designed for efficiency of development, by skipping over all boiler plate for single agent `chat` flows. It offers the same level of interactiveness as `chat` environment |
| **ambient**      | Designed for hands-off experience, when a human delegates assignment to an agent to be completed in a background. The delegation can be done directly by the human, or even via configured trigger event in GitLab platform. The human participation in `ambient` flows should be as minimal as possible |

## Quick Start

This section provides a step-by-step approach to creating your first flow.
Follow these steps to build a basic AI agent flow that can interact with the repository files and respond to user
requests.

1. Create a YAML file in [`duo_workflow_service/agent_platform/v1/flows/configs/`](duo_workflow_service/agent_platform/v1/flows/configs) which will configure your
   flow. A name of the file will become flow identifier used to trigger it later on. The file should has this basic
   structure:

   ```yaml
   version: "v1"
   environment: ambient
   components:
      - name: "my_agent" # should use alphanumeric characters or underscore. Must not include characters such as : and .
        type: AgentComponent
        prompt_id: "your_prompt_id"
        prompt_version: "^1.0.0"
        inputs: ["context:goal"]
        toolset: ["read_file", "create_file_with_contents"]
   routers:
      - from: "my_agent"
        to: "end"
   flow:
      entry_point: "my_agent"
   ```

1. Create a prompt template in the AI Gateway prompt registry at
   `ai_gateway/prompts/definitions/your_prompt_id/base/1.0.0.yml`:

   ```yaml
   name: Your prompt name
   model:
      params:
        model_class_provider: anthropic
        max_tokens: 32_768
      unit_primitives: []
   prompt_template:
      system: |
        You are GitLab Duo Chat, an agentic AI Coding assistant built by GitLab.
        Your role is to help the user complete their request by using the available tools.
        Your response style is concise and actionable.
      user: |
        Here is my task:
        {{goal}}
      placeholder: history  # See Message Placeholders section in AI Gateway Prompt Registry docs
   params:
      timeout: 180
   ```

1. Accessing the new Flow

   Currently, accessing flows via gRPC is not fully implemented.
   To use your new flow in the Duo Chat interface within VSCode, follow this workaround:

    1. In the workflow registry file `duo_workflow_service/server.py`, uncomment the line:

       ```python
       workflow_class: FlowFactory = resolve_workflow_class("<yaml_file_name_without_extension>/v1")
       ```

    1. After making this change, your new flow will be available in the Duo Chat interface for interaction in VSCode

## Component Types

### AgentComponent

The AgentComponent is the primary building block for AI-powered flows.
An AgentComponent uses a Large Language Model (LLM) to process inputs and generate responses. It provides these
capabilities:

- Execute tools to interact with the environment (read files, run commands, etc.)
- Maintain conversation history for context
- Make decisions based on the provided prompt and available tools
- Generate structured outputs that other components consume

The agent uses the prompt template from the prompt registry, processes the inputs through the LLM, and calls tools as
needed to complete its task.

#### Required Parameters

- **name**: Unique identifier for this component instance. Must not contain `:` or `.` characters.
- **type**: Must be `"AgentComponent"`
- **prompt_id**: ID of the prompt template from either the prompt registry or locally defined prompts

#### Optional Parameters

- **prompt_version**: Semantic version constraint (e.g., `"^1.0.0"`). If omitted or `null`, uses locally defined prompt
  from flow YAML.
- **inputs**: List of input data sources (default: `["context:goal"]`)
- **toolset**: List of tools available to the agent
- **ui_log_events**: UI logging configuration
- **ui_role_as**: Display role in UI (`"agent"` or `"tool"`)

#### Available Tools

Agents access the following tools in their `toolset` configuration.
Complete list of tools classes can be located at `duo_workflow_service/components/tools_registry.py`. To configure an
agent with tools, pass `name` attributes from their classes, eg: for `GetIssue` tool class pass `get_issue`
Each tool is a Python class that the agent calls to perform specific actions.

Here are some examples:

- **read_file**: Read contents of a file
- **create_file_with_contents**: Create a new file with specified content
- **edit_file**: Modify an existing file
- **list_dir**: List directory contents
- **find_files**: Search for files matching patterns

#### Prompts

Prompts define how the AI agent behaves and responds to inputs.
Every AgentComponent requires a prompt that serves as the "instructions" for the AI agent, defining its personality,
capabilities, and response patterns.
Prompts include placeholders that get replaced with actual data from the flow state.

**Important for Multi-turn Conversations:** If your AgentComponent needs access to conversation history (for context in
multi-turn interactions), include `placeholder: history` in your prompt template. This automatically provides the
component's conversation history to the AI model.

##### Prompt Sources

Flows can use prompts from two sources:

1. **File-based Prompts**: Traditional prompts stored in the AI Gateway prompt registry at
   `ai_gateway/prompts/definitions/`. Reference these using both `prompt_id` and `prompt_version` (e.g.,
   `prompt_version: "^1.0.0"`).

1. **Locally Defined Prompts**: Prompts defined directly within the flow YAML configuration. Reference these by setting
   `prompt_version: null` or omitting the `prompt_version` field entirely.

##### Locally Defined Prompts

Flows can define prompts locally within their YAML configuration, eliminating the need for separate prompt definition
files. This approach is particularly useful for flow-specific prompts or rapid prototyping.

To define prompts locally, add a `prompts` section to your flow YAML:

```yaml
version: "v1"
environment: ambient

components:
    - name: "code_analyzer"
      type: AgentComponent
      prompt_id: "my_local_prompt"
      # prompt_version omitted - uses local prompt
      ui_log_events: [ "on_agent_final_answer" ]
      inputs: ["context:goal"]
      toolset: ["read_file", "list_dir"]

prompts:
    - prompt_id: "my_local_prompt"
      model:
        params:
            model_class_provider: anthropic
            model: claude-sonnet-4-20250514
            max_tokens: 32_768
      prompt_template:
          system: "You are a helpful assistant specialized in code analysis"
          user: "{{goal}}"
          placeholder: history  # Optional: include conversation history
      params:
          timeout: 180

routers:
    - from: "code_analyzer"
      to: "end"

flow:
    entry_point: "code_analyzer"

```

**Routing Logic**: The system automatically routes between local and file-based prompts:

- `prompt_version: null` or omitted → Use local prompt from flow YAML
- `prompt_version: "^1.0.0"` → Use file-based prompt from prompt registry

**Local Prompt Structure**:

Mirrors the prompt structure of prompts taken from the prompt registry. More information about the structure can be
found [here](../aigw_prompt_registry.md#ai-gateway-prompt-configuration-reference).

**Benefits of Local Prompts**:

- **Rapid Development**: No need to create separate prompt files
- **Flow Coupling**: Prompts stay co-located with their usage
- **Simplified Testing**: Easy to iterate on prompts during development
- **Self-Contained**: Flows become more portable and self-documented

For detailed information about prompt templates and placeholder configuration, see
the [AI Gateway Prompt Registry Documentation](../aigw_prompt_registry.md#message-placeholders).

#### Inputs

Agent inputs work together with prompt placeholders to provide dynamic data to the AI.
When you define inputs in your component configuration, that data becomes available as template variables in your
prompt.

For example:

```yaml
# In your flow YAML:
inputs:
    - from: "context:user_request"
      as: "task_description"
    - from: "context:analyzer.findings"
      as: "analysis_results"
```

```yaml
# In your prompt template:
user: |
    Task: {{task_description}}
    Analysis: {{analysis_results}}
    Please provide a solution.
```

#### Outputs

Each AgentComponent automatically produces:

- **context:{component_name}.final_answer**: The agent's final response
- **conversation_history:{component_name}**: Message history
- **status**: Updated workflow status

These outputs can be used as inputs by other components or referenced in routing logic to control flow execution.
For example, you might route to different components based on whether the agent's final answer equals to specific phrase

#### UI Log Events

The AgentComponent supports the following UI log events that can be specified in the `ui_log_events` configuration:

- **on_agent_final_answer**: Logged when the agent produces its final response. This event captures the agent's
  conclusion or final output and displays it in the UI.
- **on_tool_execution_success**: Logged when a tool is successfully executed by the agent. This shows users what actions
  the agent took and their successful results.
- **on_tool_execution_failed**: Logged when a tool execution fails. This provides error information and helps with
  debugging failed operations.

#### Complete AgentComponent Example

```yaml
components:
    - name: "code_assistant"
      type: AgentComponent
      prompt_id: "code_review_helper"
      prompt_version: "^1.0.0"
      inputs: [ "context:goal" ]
      toolset:
          - "read_file"
          - "list_dir"
          - "find_files"
          - "create_file_with_contents"
          - "edit_file"
      ui_log_events:
          - "on_agent_final_answer"
          - "on_tool_execution_success"
          - "on_tool_execution_failed"
      ui_role_as: "agent"
```

## Flow Examples

### Simple ambient code review flow

```yaml
version: "v1"
environment: ambient

components:
    - name: "code_analyzer"
      type: AgentComponent
      prompt_id: "code_review_prompt"
      # prompt_version omitted - uses local prompt
      ui_log_events: ["on_agent_final_answer"]
      inputs:
        - from: context:goal
          as: mr_link
      toolset: ["read_file", "list_dir"]

prompts:
    - prompt_id: "my_local_prompt"
      model:
        params:
            model_class_provider: anthropic
            model: claude-sonnet-4-20250514
            max_tokens: 32_768
      prompt_template:
          system: "You are a experience software developer, your role is to conduct through code review and mentor other engineers on best practices and patterns."
          user: "Please conduct code review for merge request at: {{mr_link}}"
          placeholder: history  # Optional: include conversation history
      params:
          timeout: 180

routers:
    - from: "code_analyzer"
      to: "end"

flow:
    entry_point: "code_analyzer"
```

### Chat-partial flow for conversational code review foundational agent

```yaml
version: "v1"
environment: chat-partial

components:  # Exactly 1 component may be present in components section, and it must be of type AgentComponent
    - name: "code_analyzer"
      type: AgentComponent
      prompt_id: "code_review_prompt"
      # prompt_version omitted - uses local prompt
      ui_log_events: ["on_agent_final_answer"]
      inputs:
        - from: context:goal
          as: mr_link
      toolset: ["read_file", "list_dir"]

prompts:
    - prompt_id: "my_local_prompt"
      model:
        params:
            model_class_provider: anthropic
            model: claude-sonnet-4-20250514
            max_tokens: 32_768
      prompt_template:
          system: "You are a experience software developer, your role is to conduct through code review and mentor other engineers on best practices and patterns."
          user: "Please conduct code review for merge request at: {{mr_link}}"
          placeholder: history  # Optional: include conversation history
      params:
          timeout: 180

routers: []
flow: {}
```
